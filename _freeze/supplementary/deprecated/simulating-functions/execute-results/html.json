{
  "hash": "53cc1a366be9057de8ef13c98a379003",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Simulation Functions\"\nformat: \n  html:\n    toc: true\nbibliography: \"https://raw.githubusercontent.com/filippogambarota/bib-database/main/references.bib\"\ncsl: \"https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl\"\n---\n\n\n\n\nThe core of the tutorial and the set of R functions is the `sim_ord_latent()` function. Basically the function provide an intuitive way to simulate ordinal data given a dataset with predictors and a set of regression parameters on the location and scale of the latent distribution. The @lst-sim-ord-latent provide the source code of the function.^[The function depends also on other functions loaded using `devtools::load_all()`]\n\n\n```r\nsim_ord_latent <- function(location,\n                           scale = NULL,\n                           beta,\n                           zeta = NULL,\n                           prob0 = NULL, \n                           alpha = NULL, \n                           data, \n                           link = \"logit\",\n                           simulate = TRUE){\n  \n  # get all the correct functions according to the link\n  lf <- get_link(link)\n  if(is.null(alpha)){\n    # calculate thresholds if not provided\n    alpha <- prob_to_alpha(prob0, link = link)\n  }\n  k <- length(alpha) + 1 # number of ordinal outcomes\n  n <- nrow(data) # number of observations\n  \n  # model matrix for the location effect\n  Xloc <- model.matrix(location, data = data)[, -1, drop = FALSE] # remove intercept\n  lploc <- c(Xloc %*% beta) # linear predictor for the location\n  lpscale <- 0 # default scale effect 0, exp(0) = 1 (the default scale)\n  \n  # check predictors on the scale parameter\n  if(!is.null(scale)){\n    # model matrix for the scale effect\n    Xscale <- model.matrix(scale, data = data)[, -1, drop = FALSE] # remove intercept\n    lpscale <- c(Xscale %*% zeta) # linear predictor for the scale\n  }\n  \n  if(simulate){\n    # latent variable with appropriate error function\n    ystar <- lf$rfun(n, lploc, exp(lpscale))\n    \n    # cut according to thresholds\n    y <- findInterval(ystar, alpha) + 1 # to start from 1\n    \n    data$y <- ordered(y) # to ordered factor\n    data$ys <- ystar # save also the latent\n  } else{\n    alpha <- c(-Inf, alpha, Inf)\n    cp <- lapply(alpha, function(a) plogis((a - lploc) / exp(lpscale)))\n    cp <- data.frame(do.call(cbind, cp))\n    p <- data.frame(t(apply(cp, 1, diff)))\n    names(p) <- paste0(\"y\", 1:ncol(p))\n    cp <- cp[, 2:k]\n    names(cp) <- paste0(\"yp\", Reduce(paste0, 1:(k - 1), accumulate = TRUE))\n    data <- cbind(data, cp, p)\n  }\n  return(data)\n}\n```\n\n\nThe arguments are:\n\n- `location`: is an R formula `~ ...` with the predictors on the location parameters. This is expressed as in standard regression modelling `y ~ x1 + x2 + ...` but omitting the left-side of the formula. The parameters need to match columns of the `data = ` dataset.\n- `scale`: The same as the `location` but with predictors on the scale parameter of the latent distribution. By default no predictors are considered thus the scale is assumed to be the same across the dataset. By using predictors on the scale we are fitting a so-called location-scale model.\n- `beta`: Vector of regression coefficients for the location effect. These values are expressed in the scale of the link function e.g., odds ratios for a logit model. The order of the vector should match how the formula for the location is expressed\n- `zeta`: Vector of regression coefficients for the scale effect. These values are expressed in the scale of the link function e.g., odds ratios for a logit model. The order of the vector should match how the formula for the scale is expressed\n- `prob0`: vector with baseline probabilities. With baseline we intended that this vector contains the probabilities of the $k$ outcomes when all predictors are fixed to 0. For example, when $x$ is a dummy indicator for a group effect (0 for group \"a\" and 1 for group \"b\"), `prob0` is the vector of probabilities for the group \"a\". Internally this vector is converted into the vector of $k - 1$ thresholds $\\alpha_k$.\n- `alpha`: vector with $k - 1$ thresholds. This can be specified alternatively to `prob0` if we already know the thresholds.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}